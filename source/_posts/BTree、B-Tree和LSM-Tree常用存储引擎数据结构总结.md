---
title: BTree、B+Tree和LSM-Tree常用存储引擎数据结构总结
toc: true
cover: 'https://img.paulzzh.tech/touhou/random?4'
date: 2022-11-05 11:47:56
categories: 数据库
tags: [技术杂谈, 数据库]
description: BTree、B+Tree和LSM-Tree等数据结构是数据库存储引擎中及其常用的数据结构，本文讲解了这些数据结构的特点和异同；
---

BTree、B+Tree和LSM-Tree等数据结构是数据库存储引擎中及其常用的数据结构，本文讲解了这些数据结构的特点和异同；

视频地址：

-   https://www.bilibili.com/video/BV1se4y1U7Dn/

<br/>

<!--more-->

# **BTree、B+Tree和LSM-Tree常用存储引擎数据结构总结**

## **引言**

我们知道，数据有三大模块：

-   存储；
-   事物；
-   SQL解析、优化；

其中，存储模块负责数据在磁盘、内存上的存储、检索和管理，并向上层提供细粒度的数据操作接口；

同时，由于存储模块和其他模块耦合较少，因此可以将其抽象为一个专用的数据库组件，即：**存储引擎**；

![image-20221105121651187](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105121651187.png)

目前，很多数据库都支持可插拔的存储引擎，例如：MySQL支持：InnoDB、MyISAM、Memory、基于RocksDB的MyRocks等；

**对于存储而言，最重要的就是数据存储的结构（也即，数据结构！）；**

<red>**内存、缓存、读写流程的任何设计都是建立在存储结构的基础之上的！因此，存储结构和存储引擎的特性和性能关系非常密切！**</font>

相比于存储引擎而言，目前的存储结构并不是很多：

BTree 作为一个非常适合磁盘的存储结构，自关系型数据库诞生以来，一直占据主流；

而近些年来随着分布式技术的发展以及固态硬盘的发展（随机读写性能的急剧提升），LSM-Tree 越来越火热；

<br/>

## **存储引擎与存储结构**

### **存储引擎要存储什么？**

首先要明确，存储引擎要存储什么？

由于存储引擎是基于文件系统的，因此存储引擎是将一条条数据转换为具体的文件进行存储；

![image-20221105122636705](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105122636705.png)

>   **很多数据库的 /data 目录下就存储有数据文件；**

除了存储原始数据外，我们也需要将数据库中的索引组织为文件来存储；

因此，存储引擎要存储：

-   数据文件；
-   索引文件；

<br/>

### **存储引擎数据文件的组织形式**

目前主流的数据文件组织形式有三种：

-   索引组织表；
-   堆组织表；
-   哈希组织表；

<br/>

![image-20221105122751344](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105122751344.png)

**索引组织表：**

-   索引组织表将数据文件和索引文件合并在一起，如上图右上部分：
-   索引组织表直接将数据记录存储在索引文件内部；
-   如：InnoDB存储引擎；

**堆组织表：**

-   堆组织表的数据文件是一个“无序堆”（一堆数据）的数据结构，其中的数据记录一般不需要有特定顺序；
-   虽然堆组织表中的数据文件是无序的，但是我们可以通过索引文件中的索引结构来快速定位数据在堆中的位置；
-   如：Oracle、PostgreSQL；

哈希组织表：

-   将记录分散存储在一个个桶中，每条记录主键的 Hash 值来确定记录属于哪个桶；
-   记录 Hash 值的部分就是索引文件，记录 Hash 结果的部分是数据文件；

目前主流的存储引擎基本都没有使用哈希组织表；

<red>**堆组织表因为数据的插入是无序的，而索引组织表需要根据索引的顺序插入数据，因此通常情况下：**</font>

<red>**堆组织表的写入性能强于索引组织表，读取性能弱于索引组织表；**</font>

<red>**但是，`数据文件`的组织形式对于性能的影响还是比较小的，因为大多数都使用的是B树索引；**</font>

<red>**而索引作为读写数据的主要入口，`索引文件的组织形式`对于存储引擎的性能关系更加密切！**</font>

例如：

将索引文件的组织形式从 BTree 换为 LSM-Tree，则性能差异会非常大！

<red>**因此，通常情况下要重点关注的其实是：`索引文件的组织形式`！**</font>

<br/>

## **存储结构分类和发展历程**

目前，BTree和LSM-Tree 这两类存储结构在存储引擎中被使用的最为广泛，他们也分别对应了：

-   **In-place update（BTree、B+Tree）：就地更新结构，直接覆盖旧记录来存储更新内容；**
-   **Out-of-place update（LSM-Tree）：异位更新结构，会将更新的内容存储到新的位置，而不是直接覆盖旧的条目；**

如下图所示；

![image-20221105131721712](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105131721712.png)

<br/>

### **In-place update**

In-place update 对应于图（a）部分；

为了更新 key 为 k1 的 value，In-place 操作会直接涂改掉 k1，并且直接在原位置写入 (k1, v4)；

这种就地更新的结构，由于只会存储每个记录最新的版本，因此往往读性能更优，但是写入的代价会变大，因为更新会导致随机 IO；

<br/>

### **Out-of-place update**

Out-of-place update 对应于图（b）部分，在更新时，会将更新的内容存储到新的位置，而非覆盖旧的条目；

在更新 k1 的 value 并不会修改掉原（k1, v1）键值对，而是在一个新的位置写入一条新的纪录（k1, v4）；

由于这种设计通常是顺序写入，因此写入性能会更高，但是读性能会被牺牲掉：因为可能要扫描多个位置，才能读到想要的结果；

>   **例如：level-db 在读取时，会自上而下一层一层的读取直到找到首个匹配的记录；**

此外，这种数据结构还需要一个数据整合过程，来防止数据的无限膨胀，即：**Compaction 过程**；

<br/>

### **存储结构发展历程**

1970年，Rudolf Bayer 教授在《Organization and Maintenance of Large Ordered Indices》一文中提出了BTree，从他的基础上诞生了 B+Tree 等许多变种；

1996年，《The Log-Structured Merge-Tree（LSM-Tree）》论文发表，LSM-Tree 概念正式诞生；

2003年，《The Google File System（GFS）》发表，对追加的一致性保证强于改写，此后的分布式文件系统基本都更推荐使用追加写文件；

2006年，《Bigtable：A distributed strorage system for structured data》发表，相当于一个在 GFS 基础上搭建的不支持事务的分布式存储引擎，而其中的存储引擎采用的就是类似 LSM-Tree 的结构；

2014年左右，SSD 开始进入大规模商用，LSM-Tree 在SSD 上读性能得到很大提升（随机读减少了普通硬盘的寻道时间），同时LSM-Tree对SSD上的写更加友好（追加写提高了SSD的使用寿命），因此 LSM-Tree 进一步得到发展；

>   **SSD 是基于闪存进行存储的，由于闪存不能直接进行覆盖写，而必须首先擦除闪存块之后才能写入；**
>
>   **因此 LSM-Tree 追加写的特性可以完美契合其特性；**

总结一下：

BTree 作为 In-place update 模式的存储结构，在早期机械硬盘结构上表现的最好，因此占据了主流；

而随着分布式（大数据）和 SSD 技术的发展，Out-of-place update 模式的优势逐渐凸显，因此 LSM Tree 应用的越来越广泛；

<br/>

## **存储结构的共性特点**

### **存储结构需要的特性**

我们有那么多的数据结构，例如：数组、链表、Hash表等，为什么 BTree 或 LSM-Tree 能够作为存储结构呢？

![image-20221105160429281](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105160429281.png)

但是大部分都不适合作为磁盘上的存储结构，这需要考虑一下存储结构需要具有的特性：

-   1、适合磁盘存储；
-   2、允许并发操作；

首先，对于磁盘结构，顺序 IO 的性能是远远优于随机 IO 的，因此存储结构涉及到的 IO 次数越少越好，并且尽量一次读取一块连续的区域，因此从这个角度来看，存储结构的一个单元应当越大越好；

同时，存储结构应当允许并发操作，从写入并发避免数据竞争的角度来看，存储结构的单元应当越小越好；

>   **这里所说的并发操作并非数据库事务并发操作，而是内存中的数据结构；**

根据上面两个特性再审视一下之前上面列出的内存数据结构不难发现：

-   有1没2，即：只适合磁盘存储的，而不适合并发操作的：大文件、数组，他们都是一大段连续的存储区域，如果要修改，影响面很大，基本上要锁住整个数据结构！
-   有2没1，即：高并发但是不适合磁盘存储的：链表、哈希表、二叉树、红黑树等，他们的修改、写入影响小，但数据结构的粒度也非常小，一般一次只操作几个字节，不适合磁盘 IO；

那么是否存在数据结构同时满足上面两个特性呢？

当然，BTree 就是这么个数据结构；

<br/>

### **以BTree为例的In-place存储结构**

如下图所示：

![image-20221105172421905](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105172421905.png)

BTree 是一个以页为单位组织的；

首先，InnoDB 存储引擎中页的大小为 16k，一般可以指出几百上千个指针，因而具有高扇出、低高度的特点，从而保证了 BTree 是连续 IO、并且 IO 次数极少，因此适合磁盘存储；

其次，BTree 要修改的单位也是页，因此并发控制的锁在页上，BTree 并发的程度也很高；

但是并非这么简单，虽然 BTree 要修改的单位是页，但是 BTree 存在 SMO（Structure Modification Operation） 操作，即：在增删改操作可能会造成节点的分裂或者合并，此时需要操作多个磁盘块！

>   **当我们向一个页中增加数据超过其大小、或者删除数据使其空间少于二分之一时，就会造成页的分裂或者合并，影响关联节点或者父节点；**
>
>   **同时，上述影响可能还会向上传递，甚至影响到根节点！**

SMO 会导致 BTree 的并发能力并不理想；

所以，如果我们想要保证出现 SMO 操作时读写安全的话，就需要对有可能受到 SMO 操作影响的一整条链上所有节点加锁，如下图所示；

![image-20221105194306300](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105194306300.png)

**总之，虽然 BTree 有一定的并发能力，但是由于 SMO 的存在使得 BTree 的性能并不高，勉强满足并发要求，但是有很大的优化空间；**

<br/>

#### **Lock和Latch的区别（存储引擎并发操作和事务并发操作的不同）**

这里补充一下存储引擎的并发操作和事务并发操作的不同；

假设都以锁机制来控制并发，上面两种机制对应的锁分别称为：Lock 和 Latch；

![image-20221105200353910](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105200353910.png)

其中：

-   Lock：用来维持数据库事务的 ACID 特性，事务级隔离，锁住的对象为用户的数据，是一个逻辑概念，例如：共享锁、互斥锁（S、X锁）等；
-   Latch：保护数据读取过程中，加载到内存中数据结构的锁，是线程级隔离的锁；主要是防止多个线程并发去修改内存中的共享数据；

例如：

假设修改一行数据，那么首先需要将这行数据所在的页加载至内存中，随后进行修改；

而在修改前，为了防止其他线程也要来修改这页数据，需要使用 Latch 对内存数据进行上锁；加好 Latch 后，可以对数据进行修改；

此时，为了防止在事务进行提交之前，存在其他别的事务读到这行修改后未提交的数据，此时需要对数据增加 Lock；

![image-20221105195251773](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105195251773.png)

<red>**虽然 Latch 锁掉整个页数据，而 Lock 仅仅锁掉单行数据；**</font>

<red>**但是一旦完成了对这行数据的修改，那么 Latch 锁就可以释放，而 Lock 锁需要等到整个事务提交之后才能够释放！**</font>

<red>**在数据修改完成到事务提交的这段时间，Lock 就可以发挥作用了！**</font>

<red>**因此，在对数据库进行操作时，实际上是存在 Latch 和 Lock 两种锁共同生效的！但是对于用户而言，只能感觉到 Lock 锁（即，事务锁）；**</font>

<br/>

#### **Latch导致的性能损失**

虽然 Latch 的持续时间很短，但是他也会严重影响数据库性能！

![image-20221105200444258](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105200444258.png)

如上图所示为 PolarDB 在优化 InnoDB B+Tree 的 Latch 结构前后的性能对比：蓝色为原 InnoDB、绿色为优化后；

可以看到，在高并发场景下，性能提升接近三倍（即：在优化前执行 INSERT 操作可能只能达到 5w QPS，而优化后可以达到 15w QPS！）；

关于这里性能损失的原因，后文会说到！

<br/>

#### **BTree的各种变种**

刚讲了上面的内容，那么 BTree 的各种变种的优化方向大致也就是通过优化下面两个方向来设计的：

-   1、适合磁盘存储（提高粒度），IO 尽量少且一次读取连续的区域；
-   2、允许并发操作（减小粒度），增删改对存储结构的影响尽量小；

| **类型**        | **加强方向** |
| --------------- | ------------ |
| **B+Tree**      | 加强1        |
| **B-Link Tree** | 加强2        |
| **Bw Tree**     | 加强2        |

<br/>

例如，最出名的 B+Tree 在非叶子节点中仅保留指针（在 BTree 中非叶子结点也存储了行数据），所有的数据都存放在叶子节点，间接减少了树的高度；

![image-20221105210958977](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105210958977.png)

并且这样还可以区分开索引段和数据段，有助于全表扫描时的顺序IO；

总之，提升了 BTree 的特性1；

而 B-Link Tree 对 BTree 的并发控制机制做了很大的改进，提升了特性2；

对于近些年才提出的 Bw-Tree 而言，其采用了类似于 LSM-Tree 的 out-of-place update 方法，追加的写入完全无 Latch 操作（避免多线程并发写），从根本的角度上提升了特性2；

<br/>

### **以LSM-Tree为例的Out-of-place存储结构**

#### **LSM-Tree基本概念**

下面来讲解一下 LSM-Tree 在上面两个特性上的表现；

![image-20221105212603574](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105212603574.png)

对于 LSM-Tree 的结构而言：

**整体是一个分为多层、并且越向下层数据越多的层次树形结构；**

**对于写操作：**

-   **所有的写入操作都会首先直接写入内存（write）；**
-   **如果内存写满了，就会直接将内存中刚刚写入的这块数据刷入磁盘中（flush）；**
-   **当向磁盘刷入一定数量的数据之后，将本层数据和下一层数据进行合并、排序、去重；整理后的数据就放在下一层，因此就去除了数据的冗余（compaction）；**
-   **Compaction 过程可能会持续多层，并且越下层的数据就越多，最终就形成了 LST-Tree 的整体结构；**

下面来看读取操作：

![image-20221105213608874](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105213608874.png)

读取的时候需要注意：

**由于一个 key 对应的 value 可能会存在于多个层次上，此时需要以最新（更上层的）数据为准；**

**因此，在查询时需要从上至下一层层的搜索，而第一条找到的就是我们要读的结果！**

<br/>

#### **LSM-Tree结构特性**

LSM-Tree 的结构特性和 BTree 截然不同：

![image-20221105214352955](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105214352955.png)

由于其 Out-of-place 的特点：所以在正常插入到内存时，完全不会改变历史数据的结构，即：没有 SMO 过程；

因此，并发能力很强，BTree 在特性2上的瓶颈在 LSM-Tree 中不存在；

而 LSM-Tree 中每层数据都比较多，在缓冲池没有命中时，读取 LSM-Tree 时读取的次数可能会非常多！

所以，LSM-Tree 在特性1上的表现并不好！

但是，可以优化 LSM-Tree 的特性1，下面是几个常用的优化手段：

-   依靠 Compaction 操作整理 LSM-Tree 的结构，减少读 IO 的次数；
-   使用 Bloom Filter 对数据进行过滤；

>   <red>**实际上 Compaction 操作就可以看作为 LSM-Tree 的 SMO 操作！**</font>
>
>   <red>**在 Compaction 期间，不仅会占用大量资源，并且还会造成缓冲丢失、写停顿（write stall）等问题，减少并发能力；**</font>
>
>   <red>**因此，对 LSM-Tree 优化的关键点就落在 Compaction 操作上；**</font>

<br/>

### **In-place和Out-of-place update方案差异**

对于 In-place update 结构而言：

需要把磁盘中的结构加载到内存中，再修改并写回至磁盘中，因此免不了要使用 Latch 机制来做并发控制；

而对于 Out-of-place update 结构而言：

虽然存在其他因素干扰其并发能力，但是由于所有的写入都是追加操作，因此无需采用基于 Latch 的机制进行并发控制；

![image-20221105215805839](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105215805839.png)

由于现在多核处理器的发展，NUMA 模式逐渐成为主流，多核处理器在面对 Latch 的频繁获取和释放时都会损耗很多性能；

![image-20221105220406902](BTree%E3%80%81B-Tree%E5%92%8CLSM-Tree%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93.assets/image-20221105220406902.png)

可以简单理解：

CPU 中每个核都有独立的一块存储区域，而读取或者写入的过程就需要将页数据加载到这块存储区域中；这样，并发读写时，一些节点就可能会存在多个核空间中；

而加 Latch 和解 Latch 的操作又必须同步给多个核，这就造成了很大的性能损耗；

最显著的例子，对于 B+Tree 而言，在读写时由于根节点是必经之路，因此频繁的对根节点加解 Latch 就会极大的影响多核场景下的并发性能！

>   **NUMA：**
>
>   **非统一内存访问架构**（英语：**non-uniform memory access**，简称NUMA）是一种为[多处理器](https://zh.wikipedia.org/wiki/多處理器)的电脑设计的内存架构，内存访问时间取决于内存相对于处理器的位置。在NUMA下，处理器访问它自己的本地内存的速度比非本地内存（内存位于另一个处理器，或者是处理器之间共享的内存）快一些；
>
>   -   https://zh.wikipedia.org/wiki/%E9%9D%9E%E5%9D%87%E5%8C%80%E8%AE%BF%E5%AD%98%E6%A8%A1%E5%9E%8B

<br/>

## **深入了解BTree及其变种**

下面列出了 BTree 的一些变种：

-   **BTree：**
    -   **B+Tree；**
    -   **B*Tree => B-Link Tree；**
    -   **CoW BTree；**
    -   **惰性 BTree；**
    -   **Bw Tree；**

另外还有一些其他变种，例如：FD-Tree；

下面













<br/>

## **深入了解LSM-Tree及其变种**









<br/>

# **附录**

视频地址：

-   https://www.bilibili.com/video/BV1se4y1U7Dn/


<br/>
